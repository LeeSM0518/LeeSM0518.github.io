---
title: Spring AI
date: 2024-12-16 00:00:00 +0900
categories: spring
tags:
  - spring
  - ai
  - docs
  - kotlin
description: Spring AI를 활용하기 위한 Docs 정리
---

![spring-ai1](/assets/img/spring-ai1.svg)

## 1. 개요
---

`Spring AI` 는 불필요한 복잡성 없이 인공지능 기능을 통합한 애플리케이션 개발을 간소화하는 것을 목표로 한다. 즉, 애플리케이션의 데이터나 API를 AI 모델에 연결하는 기능을 제공한다.

![spring-ai2](/assets/img/spring-ai2.svg)

Spring AI는 AI 애플리케이션을 개발하기 위한 기반이 되는 추상화를 제공한다. 이로써, 최소한의 코드 변경으로 쉽게 구성 요소를 교체할 수 있다.

<br/>

## 2. 시작하기
---

> Spring AI는 Spring Boot 3.2.x 와 3.3.x 에서 지원된다.
{: .prompt-info }

<br/>

### 2.1. Snapshot 저장소와 의존 추가
---

> Spring AI는 아직 Release 버전이 존재하지 않으므로 Snapshot(개발 단계) 버전을 사용해야 한다.
{: .prompt-warning }

Snapshot 버전을 사용하려면 빌드 파일에 Spring Snapshot Repository에 대한 정보를 추가해야 한다.

<br/>

다음과 같이 Gradle 빌드 파일에 repository를 추가한다.

```kotlin
repositories {  
    mavenCentral()  
    maven("https://repo.spring.io/snapshot")  
}
```
{: file="build.gradle.kts"}

<br/>

다음과 같이 Gradle 빌드 파일에 의존을 추가한다.

```kotlin
dependencies {  
    implementation("org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-SNAPSHOT")
}
```
{: file="build.gradle.kts"}

<br/>

다음과 같이 사용할 AI 서비스의 API Key를 등록한다.

```yaml
spring:  
  ai:  
    openai:  
      api-key: {API키}
```
{: file="application.yaml"}

<br/>

## 3. Chat Client API
---

ChatClient는 AI 모델과 통신하기 위한 API를 제공한다.

API에는 AI 모델에 입력으로 전달되는 프롬프트의 구성 요소를 구축하는 방법이 있다. `Prompt` 에는 AI 모델의 출력 및 동작을 안내하는 텍스트가 포함되어 있다.

AI 모델은 메시지의 두 유형의 메시지를 처리한다.
1. `user` 메시지 : 사용자로부터 입력된 메시지
2. `system` 메시지 : 대화를 안내하기 위해 시스템이 생성한 메시지

<br/>

### 3.1. ChatClient 생성
---

`ChatClient` 는 `ChatClient.Builder` 객체를 활용해 생성할 수 있다. Spring Boot 자동 구성으로 생성된 `ChatClient.Builder` 인스턴스를 얻거나 프로그래밍 방식으로 생성할 수 있다.

<br/>

#### 3.1.1. 자동 구성된 ChatClient 사용

다음과 같이 `ChatClient.Builder` 를 주입하여 사용하면 된다.

```kotlin
@Component  
class ChatAiAdapter(builder: ChatClient.Builder) {

	private val chatClient: ChatClient = builder.build()
  
    suspend fun generation(userInput: String): String? =  
        chatClient  
            .prompt()  
            .user(userInput)  
            .call()  
            .content()  
}
```
- `call()` : AI 모델로 요청 전송
- `content()` : AI 모델의 응답을 반환

<br/>

#### 3.1.2. 직접 ChatClient 생성

`ChatClient.Builder` 의 자동 구성을 비활성화 하려면 예시와 같이 설정값을 변경하면 된다. (ex. `spring.ai.chat.client.enabled=false` ) 이러한 설정은 여러 대화 모델을 같이 사용할 때 유용하다.
이후, 다음과 같이 `ChatClient.Builder` 인스턴스를 통해 `ChatModel` 을 생성한다.
```kotlin
// 주로 자동 주입하여 사용
val myChatModel: ChatModel = ...

val builder: ChatClient.Builder = ChatClient.builder(this.myChatModel)

val chatClient: ChatClient = ChatClient.create(this.myChatModel)
```

<br/>

### 3.2. ChatClient Fluent API
---

다음과 같이 프롬프트를 만들 수 있다.

- `prompt()`
- `prompt(Prompt prompt)`
- `prompt(String content)`

<br/>

### 3.3. ChatClient 응답
---

`ChatClient` 여러 응답 포맷을 제공한다.

<br/>

#### 3.3.1. ChatResponse

본 응답에는 생성된 방법에 대한 메타데이터가 포함된다. 메타데이터에는 응답을 만드는 데 사용된 토큰의 수가 포함된다.

다음과 같이 `call()` 메서드 뒤에 `chatResponse()` 를 호출하여 객체를 반환할 수 있다.

```kotlin
chatClient  
    .prompt()  
    .user(userInput)  
    .call()  
    .chatResponse()
```

<br/>

#### 3.3.2. Entity

다음과 같이 `entity()` 메서드를 통해 엔티티로 매핑하여 응답할 수 있다.

```kotlin
data class Result(  
    val result: String,  
)  
  
suspend fun generation(userInput: String): Result? =  
    chatClient  
        .prompt()  
        .user(userInput)  
        .call()  
        .entity(Result::class.java)
```

<br/>

#### 3.3.3. Streaming

다음과 같이 `stream()` 메서드를 통해 비동기로 응답 받을 수 있다.

```kotlin
suspend fun generation(userInput: String): Flux<String> =  
    chatClient  
        .prompt()  
        .user(userInput)  
        .stream()  
        .content()
```

<br/>

다음과 같이 엔티티로 변환할 수도 있다.

```kotlin
val converter = BeanOutputConverter(object : ParameterizedTypeReference<List<Result>>() {})  
  
suspend fun generation(userInput: String): List<Result>? =  
    chatClient  
        .prompt()  
        .user(userInput)  
        .stream()  
        .content()  
        .collectList()  
        .awaitSingle()  
        ?.joinToString("")  
        ?.let { converter.convert(it) }
```

<br/>

### 3.4. `call()` 응답
---

`ChatClinet` 의 `call()` 메서드 호출 후 여러 타입으로 응답 받을 수 있다.

- `String content()` : 문자열 내용
- `ChatResponse chatResponse()` : 메타데이터가 포함된 `ChatResponse` 객체
- `entity()` 
	- `entity(ParameterizedTypeReference<T> type)` : 엔티티 타입의 `Collection` 을 반환
	- `entity(Class<T> type)` : 특정 엔티티 타입으로 반환
	- `entity(StructuredOutputConverter<T> converter)` : `String` 을 엔티티 타입으로 변환한 객체

`call()` 대신에 `stream()` 메서드를 사용할 수도 있다.

<br/>

### 3.5. `stream()` 응답
---

`ChatClient` 의 `stream()` 메서드 호출 후 여러 타입으로 응답 받을 수 있다.

- `Flux<String> content()` : 문자열의 `Flux`
- `Flux<ChatResponse> chatResponse()` : `ChatResponse` 객체의 `Flux`

<br/>

### 3.6. 기본값 사용
---

`@Configuration` 클래스에서 기본 시스템 텍스트로 `ChatClient` 를 생성하면 생성 코드를 간소화 할 수 있다. 기본값을 설정하면 `ChatClient` 를 호출할 때 사용자 텍스트만 지정하면 되므로 각 요청에 대한 시스템 텍스트를 설정할 필요가 없다.

<br/>

#### 3.6.1. 기본 시스템 텍스트
---

다음과 같이 기본 시스템 텍스트를 설정할 수 있다.

```kotlin
@Configuration  
class ChatClientConfiguration(  
    val builder: ChatClient.Builder  
) {  
  
    @Bean  
    fun chatClient(): ChatClient =  
        builder  
            .defaultSystem("You are a friendly chat bot that answers question in the voice of a Pirate")  
            .build()  
}
```

<br/>

그리고 다음과 같이 사용할 수 있다.

```kotlin
@RestController  
class ChatAiAdapter(  
    private val chatClient: ChatClient,  
) {  
  
    @GetMapping("/ai/simple")  
    suspend fun completion(  
        @RequestParam(value = "message", defaultValue = "Tell me a joke")  
        message: String,  
    ): Map<String, String?> =  
        mapOf("completion" to chatClient.prompt().user(message).call().content())  
  
}
```

<br/>

API를 호출한 결과는 다음과 같다.

```
GET http://localhost:8080/ai/simple?message=hello

HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 129

{
  "completion": "Ahoy, matey! How be ye this fine day on the seven seas? What be the treasure ye seek from this ole pirate? Arrr!"
}
```

<br/>

#### 3.6.2. 파라미터 기반 기본 시스템 텍스트
---

다음과 같이 시스템 텍스트에 placeholder를 사용하여 파라미터를 전달할 수도 있다.

```kotlin
@Configuration  
class ChatClientConfiguration(  
    val builder: ChatClient.Builder  
) {  
  
    @Bean  
    fun chatClient(): ChatClient =  
        builder  
            .defaultSystem("You are a friendly chat bot that answers question in the voice of {voice}")  
            .build()  
}
```

```kotlin
@RestController  
class ChatAiAdapter(  
    private val chatClient: ChatClient,  
) {  
  
    @GetMapping("/ai/simple")  
    suspend fun completion(  
        @RequestParam(value = "message", defaultValue = "Tell me a joke")  
        message: String,  
        @RequestParam(value = "voice")  
        voice: String,  
    ): Map<String, String?> =  
        mapOf("completion" to  
                chatClient  
                    .prompt()  
                    .system { it.param("voice", voice) }  
                    .user(message)  
                    .call()  
                    .content()  
        )  
  
}
```

```
GET http://localhost:8080/ai/simple?message=hello&voice='Robert De Niro'

HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 53

{
  "completion": "Hey, how you doin'? What's goin' on?"
}
```

<br/>

#### 3.6.3. 다른 기본값들
---

`ChatClient.Builder` 에서 기본 프롬프트 구성을 지정할 수 있다.

- `defaultOptions(ChatOptions chatOptions)` : `ChatOptions` 나 모델 특화된 `OpenAiChatOptions` 등을 지정할 수 있다.
- `defaultFunctions(String name, String description, Function<I, O> function)` : `name` 은 사용자 텍스트에서 함수를 참조하는 데 사용된다. `description` 은 함수의 목적을 설명하고 AI 모델이 정확한 응답을 할 수 있도록 한다. `function` 는 필요할 때 모델이 실행하는 함수 인스턴스이다.
- `defaultFunctions(String... functionsNames)`
- `defaultUser` : 사용자 텍스트를 정의
- `defaultAdvisors` : `prompt` 를 만드는 데 사용된 데이터를 수정하는 것을 허용한다. 

<br/>

### 3.7. Advisors
---

Advisors API는 Spring 애플리케이션에서 AI 기반 상호작용을 인터셉트, 수정, 향상시키는 방법이다.

사용자 텍스트로 AI 모델을 호출할 때 일반적인 패턴은 프롬프트에 문맥별 데이터를 추가하거나 증가시키는 것이다.

문맥 데이터는 여러 유형이 될 수 있다. 일반적인 유형은 다음과 같다.
- **개인 데이터** : AI 모델이 훈련받지 않은 데이터이다.
- **대화 내역** : 이전 대화 내용이 응답을 생성할 때 고려하도록 하려면 요청과 함께 이전 대화 내용을 보내야 한다.

<br/>

#### 3.7.1. ChatClient에 Advisor 설정
---

ChatClient fluen API는 advisors를 설정하기 위한 `AdvisorSpec` 인터페이스를 제공한다. 해당 인터페이스는 advisor 를 추가하는 메서드들을 지원한다.

```java
interface AdvisorSpec {
    AdvisorSpec param(String k, Object v);
    AdvisorSpec params(Map<String, Object> p);
    AdvisorSpec advisors(Advisor... advisors);
    AdvisorSpec advisors(List<Advisor> advisors);
}
```

<br/>

> 어드바이저 체인에 추가되는 순서는 어드바이저의 실행 순서를 결정하기 때문에 매우 중요하다.
{: .prompt-danger }

```kotlin
builder  
    .build()  
    .prompt()  
    .advisors(  
        MessageChatMemoryAdvisor(chatMemory),  
        QuestionAnswerAdvisor(vectorStore, SearchRequest.defaults())  
    )  
    .user(userText)  
    .call()  
    .content()
```
- 이 구성에서는 `MessageChatMemoryAdvisor` 가 먼저 실행되어 대화 내역이 프롬프트에 추가된다.
- 그 후, `QuestionAnswerAdvisor` 는 사용자의 질문과 추가된 대화 기록을 기반으로 검색을 수행하여 더욱 관련성 있는 결과를 제공할 가능성이 있다.

<br/>

#### 3.7.2. 검색 증강 생성 (RAG, Retrieval Augmented Generation)
---

벡터 데이터베이스는 AI 모델이 인식하지 못하는 데이터를 저장한다. 사용자 질문이 AI 모델에 전송되면 `QuestionAnswerAdvisor` 가 벡터 데이터베이스에서 사용자 질문과 관련된 문서를 쿼리한다.

벡터 데이터베이스의 응답은 사용자 텍스트에 추가되어 AI 모델이 응답을 생성할 수 있는 맥락을 제공한다.

이미 `VectorStore` 에 데이터를 로드했다고 가정하면 `ChatClient` 에 `QuestionAnswerAdvisor` 인스턴스를 제공하여 검색 증강 생성(RAG)을 수행할 수 있다.

```kotlin
builder  
    .build()  
    .prompt()  
    .advisors(  
        MessageChatMemoryAdvisor(chatMemory),  
        QuestionAnswerAdvisor(vectorStore, SearchRequest.defaults())  
    )  
    .user(userText)  
    .call()  
    .chatResponse()
```
- `SearchRequest.defaults()` 는 벡터 데이터베이스의 모든 문서에 대한 유사성 검색을 수행한다.
- 검색되는 문서 유형을 제한하기 위해 `SearchRequest` 는 모든 `VectorStore` 에서 이식 가능한 SQL과 유사한 필터 표현식을 사용한다.

<br/>

**동적 필터 표현식**

`FILTER_EXPRESSION` advisor 컨텍스트 매개변수를 사용하여 런타임에 `SearchRequest` 필터 표현식을 수정한다.

```kotlin
val chatClient: ChatClient = 
  ChatClient
    .builder(chatModel)
    .defaultAdvisors(new QuestionAnswerAdvisor(vectorStore, SearchRequest.defaults()))
    .build();

// Update filter expression at runtime
val content: String = 
  chatClient
    .prompt()
    .user("Please answer my question XYZ")
    .advisors(a -> a.param(QuestionAnswerAdvisor.FILTER_EXPRESSION, "type == 'Spring'"))
    .call()
    .content();
```
- 검색 결과를 동적으로 필터링할 수 있다.

<br/>

#### 3.7.3. Chat Memory
---

`ChatMemory` 인터페이스는 대화 내역을 위한 저장소이다. 대화에 메시지를 추가하고, 대화에서 메시지를 검색하고, 대화 내역을 지우는 방법을 제공한다.

현재 채팅 대화 내역을 메모리에 저장하고, 각각 `time-to-live` 로 저장하는 `InMemoryChatMemory` 와 `CassandraChatMemory` 라는 두 가지 구현체가 있다.

다음과 같이 `time-to-live` 를 사용하여 `CassandraChatMemory` 를 생성할 수 있다.

```kotlin
CassandraChatMemory
  .create(
    CassandraChatMemoryConfig
      .builder()
      .withTimeToLive(Duration.ofDays(1)
  )
  .build()
```

<br/>

다음 어드바이저 구현체들은 대화 내역을 프롬프트에 어드바이스하기 위해 `ChatMemory` 인터페이스를 사용한다. 
- `MessageChatMemoryAdvisor`, `PromptChatMemoryAdvisor`, `VectoreStoreChatMemoryAdvisor`
  - 자세한 내용은 Spring AI Docs 참고

<br/>

#### 3.7.4. 로깅
---

`SimpleLoggerAdvisor` 는 `ChatClient` 의 `request` 및 `response` 데이터를 기록하는 어드바이저이다. 이는 AI 상호작용을 디버깅하고 모니터링하는 데 유용하다.

로깅을 활성화하려면 ChatClient를 생성할 때 `SimpleLoggerAdvisor` 를 advisor 체인에 추가하면 된다.

```kotlin
@Configuration  
class ChatClientConfiguration(  
    val builder: ChatClient.Builder  
) {  
  
    @Bean  
    fun chatClient(): ChatClient =  
        builder  
            .defaultAdvisors(SimpleLoggerAdvisor())  
            .build()  
}
```

로그를 보려면 advisor 패키지의 로깅 수준을 `DEBUG` 로 설정하면 된다.

```yaml
logging:  
  level:  
    org.springframework.ai.chat.client.advisor: DEBUG
```
{: file="application.yaml"}

<br/>

## 4. AI Models (OpenAI)
---

### 4.1. 필수 조건
---

OpenAI에 가입한 후에 API Key를 생성해야 한다. 해당 키를 `spring.ai.openai.api-key` 에 설정해야 한다.

<br/>

### 4.2. 자동 설정
---

다음 의존을 사용하면 OpenAI Chat Client가 자동으로 설정된다.

```kotlin
dependencies {  
    implementation("org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-SNAPSHOT")  
}
```
{: file="build.gradle.kts"}

<br/>

#### 4.2.1. 대화 설정

**재시도 프로퍼티**

`spring.ai.retry` 는 OpenAI 채팅 모델의 재시도 메커니즘을 구성할 수 있는 속성이다.

|Property|Description|Default|
|---|---|---|
|spring.ai.retry.max-attempts|재시도 최대 횟수|10|
|spring.ai.retry.backoff.initial-interval|재시도 하기 전 대기 시간|2 sec.|
|spring.ai.retry.backoff.multiplier|재시도 대기시간 증가 비율|5|
|spring.ai.retry.backoff.max-interval|재시도 최대 시간|3 min.|
|spring.ai.retry.on-client-errors|클라이언트 오류에 대해 재시도를 시도할지 여부|false|
|spring.ai.retry.exclude-on-http-codes|재시도를 트리거하지 않아야 하는 HTTP 상태 코드|empty|
|spring.ai.retry.on-http-codes|재시도를 트리거해야 하는 HTTP 상태 코드|empty|

<br/>

**연결 프로퍼티**

`spring.ai.openai` 는 OpenAI의 연결 속성이다.

|Property|Description|Default|
|---|---|---|
|spring.ai.openai.base-url|연결 URL|[api.openai.com](https://api.openai.com/)|
|spring.ai.openai.api-key|API Key|-|
|spring.ai.openai.organization-id|조직 ID|-|
|spring.ai.openai.project-id|프로젝트 ID|-|

<br/>

**설정 프로퍼티**

`spring.ai.openai.chat` 은 OpenAI의 채팅 모델을 설정할 수 있는 속성이다.

|Property|Description|Default|
|---|---|---|
|spring.ai.openai.chat.enabled|Enable OpenAI chat model.|true|
|spring.ai.openai.chat.base-url|Optional override for the `spring.ai.openai.base-url` property to provide a chat-specific URL.|-|
|spring.ai.openai.chat.completions-path|The path to append to the base URL.|`/v1/chat/completions`|
|spring.ai.openai.chat.api-key|Optional override for the `spring.ai.openai.api-key` to provide a chat-specific API Key.|-|
|spring.ai.openai.chat.organization-id|Optionally, you can specify which organization to use for an API request.|-|
|spring.ai.openai.chat.project-id|Optionally, you can specify which project to use for an API request.|-|
|spring.ai.openai.chat.options.model|Name of the OpenAI chat model to use. You can select between models such as: `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-3.5-turbo`, and more. See the [models](https://platform.openai.com/docs/models) page for more information.|`gpt-4o`|
|spring.ai.openai.chat.options.temperature|The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify `temperature` and `top_p` for the same completions request as the interaction of these two settings is difficult to predict.|0.8|
|spring.ai.openai.chat.options.frequencyPenalty|Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.|0.0f|
|spring.ai.openai.chat.options.logitBias|Modify the likelihood of specified tokens appearing in the completion.|-|
|spring.ai.openai.chat.options.maxTokens|(Deprecated in favour of `maxCompletionTokens`) The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model’s context length.|-|
|spring.ai.openai.chat.options.maxCompletionTokens|An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens.|-|
|spring.ai.openai.chat.options.n|How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as 1 to minimize costs.|1|
|spring.ai.openai.chat.options.output-modalities|Output types that you would like the model to generate for this request. Most models are capable of generating text, which is the default. The `gpt-4o-audio-preview` model can also be used to generate audio. To request that this model generate both text and audio responses, you can use: `text`, `audio`. Not supported for streaming.|-|
|spring.ai.openai.chat.options.output-audio|Audio parameters for the audio generation. Required when audio output is requested with `output-modalities`: `audio`. Requires the `gpt-4o-audio-preview` model and is is not supported for streaming completions.|-|
|spring.ai.openai.chat.options.presencePenalty|Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics.|-|
|spring.ai.openai.chat.options.responseFormat.type|Compatible with `GPT-4o`, `GPT-4o mini`, `GPT-4 Turbo` and all `GPT-3.5 Turbo` models newer than `gpt-3.5-turbo-1106`. The `JSON_OBJECT` type enables JSON mode, which guarantees the message the model generates is valid JSON. The `JSON_SCHEMA` type enables [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs) which guarantees the model will match your supplied JSON schema. The JSON_SCHEMA type requires setting the `responseFormat.schema` property as well.|-|
|spring.ai.openai.chat.options.responseFormat.name|Response format schema name. Applicable only for `responseFormat.type=JSON_SCHEMA`|custom_schema|
|spring.ai.openai.chat.options.responseFormat.schema|Response format JSON schema. Applicable only for `responseFormat.type=JSON_SCHEMA`|-|
|spring.ai.openai.chat.options.responseFormat.strict|Response format JSON schema adherence strictness. Applicable only for `responseFormat.type=JSON_SCHEMA`|-|
|spring.ai.openai.chat.options.seed|This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.|-|
|spring.ai.openai.chat.options.stop|Up to 4 sequences where the API will stop generating further tokens.|-|
|spring.ai.openai.chat.options.topP|An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both.|-|
|spring.ai.openai.chat.options.tools|A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.|-|
|spring.ai.openai.chat.options.toolChoice|Controls which (if any) function is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function. Specifying a particular function via `{"type: "function", "function": {"name": "my_function"}}` forces the model to call that function. `none` is the default when no functions are present. `auto` is the default if functions are present.|-|
|spring.ai.openai.chat.options.user|A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.|-|
|spring.ai.openai.chat.options.functions|List of functions, identified by their names, to enable for function calling in a single prompt requests. Functions with those names must exist in the `functionCallbacks` registry.|-|
|spring.ai.openai.chat.options.stream-usage|(For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value.|false|
|spring.ai.openai.chat.options.parallel-tool-calls|Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling) during tool use.|true|
|spring.ai.openai.chat.options.http-headers|Optional HTTP headers to be added to the chat completion request. To override the `api-key` you need to use an `Authorization` header key, and you have to prefix the key value with the `Bearer ` prefix.|-|
|spring.ai.openai.chat.options.proxy-tool-calls|If true, the Spring AI will not handle the function calls internally, but will proxy them to the client. Then is the client’s responsibility to handle the function calls, dispatch them to the appropriate function, and return the results. If false (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support|false|



## Reference
---

[Spring: Spring AI](https://docs.spring.io/spring-ai/reference/index.html)